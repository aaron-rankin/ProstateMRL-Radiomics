{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in patient key\n",
    "root = UF.DataRoot(2)\n",
    "LimbusKey = pd.read_csv(root + \"\\\\Aaron\\\\ProstateMRL\\\\Code\\\\Extraction\\\\PatKeys\\\\LimbusKey.csv\")\n",
    "AllKey = pd.read_csv(root + \"\\\\Aaron\\\\ProstateMRL\\\\Code\\\\Extraction\\\\PatKeys\\\\AllPatientKey_s.csv\")\n",
    "\n",
    "# Loop through treatments\n",
    "treatments = AllKey[\"Treatment\"].unique()\n",
    "new_key = pd.DataFrame()\n",
    "for t in treatments:\n",
    "    AllKey_t = AllKey[AllKey[\"Treatment\"] == t]\n",
    "    LimbusKey_t = LimbusKey[LimbusKey[\"Treatment\"] == t]\n",
    "\n",
    "    # Loop through patients\n",
    "    patIDs = LimbusKey_t[\"PatID\"].unique()\n",
    "\n",
    "    for pat in patIDs:\n",
    "        pat_L = LimbusKey_t[LimbusKey_t[\"PatID\"] == pat]\n",
    "        pat_A = AllKey_t[AllKey_t[\"PatID\"] == pat]\n",
    "        print(pat_A)\n",
    "        print(pat_L)\n",
    "        # add date and days column from all to limbus key based on Scan\n",
    "        for i in range(len(pat_L)):\n",
    "            scan = pat_L.iloc[i][\"Scan\"]\n",
    "            fraction = pat_A.iloc[i][\"Fraction\"]\n",
    "            date = pat_A[pat_A[\"Scan\"] == scan][\"Date\"].values[0]\n",
    "            days = pat_A[pat_A[\"Scan\"] == scan][\"Days\"].values[0]\n",
    "            pat_L.at[pat_L.index[i], \"Date\"] = str(date)\n",
    "            pat_L.at[pat_L.index[i], \"Days\"] = int(days)\n",
    "            pat_L.at[pat_L.index[i], \"Fraction\"] = int(fraction)\n",
    "\n",
    "        pat_L[\"Days\"] = pat_L[\"Days\"].astype(int)\n",
    "        # sort by days\n",
    "        pat_L = pat_L.sort_values(by=[\"Fraction\"])\n",
    "\n",
    "    # add to new key\n",
    "        new_key = new_key.append(pat_L)\n",
    "\n",
    "new_key.to_csv(root + \"\\\\Aaron\\\\ProstateMRL\\\\Code\\\\Extraction\\\\PatKeys\\\\LimbusKey_s.csv\", index=False)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "csvs = os.listdir(\"E:\\\\Aaron\\ProstateMRL\\Data\\Paper1\\HM-FSTP\\\\Longitudinal\\ClusterLabels\\\\\")\n",
    "#csvs = [csv for csv in csvs if \"HM\" in csv]\n",
    "\n",
    "fts_s = pd.read_csv(\"E:\\\\Aaron\\ProstateMRL\\Data\\Paper1\\\\HM-FSTP\\\\Features\\\\SelectedFeatures_Longitudinal.csv\")\n",
    "fts_s = fts_s[\"Feature\"].values\n",
    "for csv in csvs:\n",
    "    df = pd.read_csv(\"E:\\\\Aaron\\ProstateMRL\\Data\\Paper1\\\\HM-FSTP\\\\Longitudinal\\ClusterLabels\\\\\" + csv)\n",
    "    pat = str(csv)[:-4]\n",
    "    df[\"Selected\"] = df[\"Feature\"].apply(lambda x: x in fts_s)\n",
    "    # print where selected is True\n",
    "    df = df[['Feature', 'Cluster', 'Fraction', 'FeatureChange', 'Selected']]\n",
    "    df['Feature'] = df['Feature'].str.replace('original_', '')\n",
    "    clusters = df[\"Cluster\"].unique()\n",
    "    clusters = sorted(clusters, key=lambda x: int(x))\n",
    "    for c in clusters:\n",
    "        df_c = df[df[\"Cluster\"] == c]\n",
    "        df_c = df_c.sort_values(by = [\"Fraction\"])\n",
    "\n",
    "        # get selected features\n",
    "        selected_fts = df_c[df_c[\"Selected\"] == True][\"Feature\"].unique()\n",
    "        if len(selected_fts) == 0:\n",
    "            sf_str = \"No features selected\"\n",
    "        \n",
    "        number_fts = \"Total number of feature(s) in Cluster {}: {}\\nNumber of selected features: {}\\n\".format(c, df_c[\"Feature\"].nunique(), len(selected_fts) )\n",
    "        text_str = selected_fts\n",
    "        text_str = '\\n'.join(text_str)\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.7)\n",
    "        fts = df_c[\"Feature\"].values\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.title(\" Cluster \" + str(c))\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        sns.set_context(\"paper\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "        for ft in fts:\n",
    "            df_ft = df_c[df_c[\"Feature\"] == ft]\n",
    "            values = df_ft[\"FeatureChange\"].values\n",
    "            fractions = df_ft[\"Fraction\"].values\n",
    "            colour = \"blue\" if df_ft[\"Selected\"].values[0] else \"grey\"\n",
    "            l = df_ft[\"Feature\"].values[0]\n",
    "            plt.plot(fractions, values, label = l, color = colour)\n",
    "            #plt.scatter(fractions, values, color = colour)\n",
    "        plt.xlabel(\"Fraction\", fontsize = 20)\n",
    "        plt.ylabel(\"Feature Change\", fontsize = 20)\n",
    "        plt.xticks(np.arange(1, 5.1, 1))\n",
    "        plt.xlim(1, 5)\n",
    "        #plt.ylim(-1, 1)\n",
    "        # add text box\n",
    "        #plt.text(0.05, 0.95, (number_fts + text_str), transform=plt.gca().transAxes, fontsize=14, verticalalignment='top', bbox=props)\n",
    "        \n",
    "        #plt.legend(title = \"Feature Selected\", bbox_to_anchor=(1, 0.6), labels = [\"Yes\", \"No\"])\n",
    "        plt.title(\"Cluster \" + str(c), fontsize = 30)\n",
    "        plt.savefig(\"E:\\\\Aaron\\ProstateMRL\\Data\\Paper1\\HM-FSTP\\Longitudinal\\ClusterPlots\\\\Run2_\" + str(pat) + \"_Cluster\" + str(c) + \".png\", bbox_inches = \"tight\")\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dir = \"E:\\\\Aaron\\\\ProstateMRL\\\\Data\\\\Paper1\\\\NormSummary\\\\\"\n",
    "\n",
    "files = os.listdir(dir)\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    # loop through txt files and get lines that contain Before:\n",
    "    with open(dir + file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        # filter so only lines with Before: are kept\n",
    "        # get line with \n",
    "        lines = [line for line in lines if \"Longitudinal\" in line]\n",
    "\n",
    "        r_lines = [line for line in lines if \"Removed:\" in line]\n",
    "        s_line = [line for line in lines if \"Selected:\" in line]\n",
    "        \n",
    "        ICC = int(r_lines[0][-3:])\n",
    "        Vol = int(r_lines[1][-3:])\n",
    "        Sel = int(s_line[0][-3:])\n",
    "\n",
    "        result = result.append({\"Norm\": file[:-4], \"ICC\": ICC, \"Volume\": Vol, \"Selected\": Sel}, ignore_index=True) \n",
    "result = result.melt(id_vars=[\"Norm\"], var_name=\"Stage\", value_name=\"Number\")\n",
    "\n",
    "# order result so plot is in correct order\n",
    "result[\"Norm\"] = pd.Categorical(result[\"Norm\"], [\"Raw\", \"HM-FS\", \"HM-TP\", \"HM-FSTP\", \"Med-Pros\", \"Med-Psoas\"])\n",
    "result[\"Stage\"] = pd.Categorical(result[\"Stage\"], [\"ICC\", \"Volume\", \"Selected\"])\n",
    "\n",
    "# bar plot results\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "sns.barplot(x=\"Norm\", y=\"Number\", data=result, hue=\"Stage\")\n",
    "plt.xlabel(\"Normalisation\", fontsize = 20)\n",
    "plt.ylabel(\"Number of Features\", fontsize = 20)\n",
    "plt.title(\"Number of Features Removed or Selected\", fontsize = 26)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"E:\\\\Aaron\\ProstateMRL\\Code\\PatKeys\\\\MedianSignalNorm.csv\")\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "# pick a random patient\n",
    "pat = df[\"PatID\"].sample().values[0]\n",
    "\n",
    "# change Mask variables to Prostate and Psoas\n",
    "df[\"Mask\"] = df[\"Mask\"].apply(lambda x: \"Prostate\" if x == \"shrunk_pros\" else \"Psoas\")\n",
    "df = df[df[\"PatID\"] == pat]\n",
    "# plot signal over time for each normalisation in facet grid\n",
    "g = sns.FacetGrid(df, col=\"Norm\", hue=\"Mask\", col_wrap=3, height=5, aspect=1.5)\n",
    "g.map(sns.lineplot, \"Scan\", \"Median\", marker=\"o\")\n",
    "g.set_axis_labels(\"Fraction\", \"Median Signal\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.add_legend()\n",
    "plt.suptitle(\"Median Signal for Patient \" + str(pat), fontsize = 30)\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "root = \"E:\\\\\"\n",
    "Norm = \"HM-FS\"\n",
    "\n",
    "#df_all = pd.read_csv(root + \"Aaron\\ProstateMRL\\Data\\Paper1\\\\\" + Norm + \"\\\\Features\\\\Longitudinal_All_fts_Baseline.csv\")\n",
    "# remove minimum feature\n",
    "df_all = pd.read_csv(root + \"Aaron\\ProstateMRL\\Data\\Paper1\\\\\" + Norm + \"\\\\Features\\\\Longitudinal_Limbus_fts_Baseline.csv\")\n",
    "df_all = df_all[df_all[\"Feature\"] != \"original_firstorder_Minimum\"]\n",
    "\n",
    "\n",
    "df_res = pd.DataFrame()\n",
    "for ft in tqdm(df_all[\"Feature\"].unique()):\n",
    "    df_ft = df_all[df_all[\"Feature\"] == ft]\n",
    "    ft_vals = df_ft[\"FeatureValue\"].values\n",
    "    ft_change = df_ft[\"FeatureChange\"].values\n",
    "    \n",
    "    ft_vals01 = preprocessing.minmax_scale(ft_vals, feature_range=(0, 1))\n",
    "    ft_change01 = preprocessing.minmax_scale(ft_change, feature_range=(0, 1))\n",
    "    \n",
    "    df_ft.loc[df_all[\"Feature\"] == ft, \"FeatureValue\"] = ft_vals01\n",
    "    df_ft.loc[df_all[\"Feature\"] == ft, \"FeatureChange\"] = ft_change01\n",
    "    # append \n",
    "    df_res = df_res.append(df_ft, ignore_index=True)\n",
    "\n",
    "df_res.to_csv(root + \"Aaron\\ProstateMRL\\Data\\Paper1\\\\\" + Norm + \"\\\\Features\\\\Longitudinal_Limbus_fts_BaselineRS.csv\")\n",
    "\n",
    "    \n",
    "\n",
    "# pivot table so feature values and changes are in columns\n",
    "# plot features over time for each patient in facet grid\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot df long \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df_l = df_all.melt(id_vars=[\"PatID\", \"Scan\", \"Mask\", \"Fraction\", \"Days\", \"Feature\"], var_name=\"FeatureType\", value_name=\"Value\")\n",
    "\n",
    "df_l = df_l[df_l[\"FeatureType\"].isin([\"FeatureRS11\", \"FeatureRS01\", \"FeatureChangeRS11\", \"FeatureChangeRS01\"])]\n",
    "# add small random noise to fraction to avoid overlapping points\n",
    "df_l[\"Fraction\"] = df_l[\"Fraction\"] + np.random.normal(0, 0.05, df_l.shape[0])\n",
    "\n",
    "# plot features over time for each patient in facet grid\n",
    "for ft in df_l[\"Feature\"].unique()[0:10]:\n",
    "    df_l_ft = df_l[df_l[\"Feature\"] == ft]\n",
    "    g = sns.FacetGrid(df_l_ft, col=\"PatID\", hue=\"FeatureType\", col_wrap=5, height=5, aspect=1.5)\n",
    "    g.map(sns.lineplot, \"Fraction\", \"Value\", marker=\"o\")\n",
    "    g.set_axis_labels(\"Fraction\", \"Feature Value\")\n",
    "    g.set_titles(\"{col_name}\")\n",
    "    g.add_legend()\n",
    "    plt.suptitle(ft, fontsize = 30)\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def ClusterCount(root, Norm, output, tag):\n",
    "    '''\n",
    "    Summarises clustering results\n",
    "    '''\n",
    "    patIDs = ['653', '713', '752', '826', '1088', '1089', '1118', '1303', '1307', '1464', '1029',\n",
    "    '1302', '1431', '1481', '1540', '1553', '1601', '1642', '829', '955']\n",
    "    dir = root + \"\\\\Aaron\\\\ProstateMRL\\\\Data\\\\Paper1\\\\\" + Norm + \"\\\\Longitudinal\\\\ClusterLabels\\\\\"\n",
    "    #patIDs = UF.SABRPats()\n",
    "    df_result = pd.DataFrame()\n",
    "\n",
    "    for pat in patIDs:\n",
    "\n",
    "        df = pd.read_csv(root + \"\\\\Aaron\\\\ProstateMRL\\\\Data\\\\Paper1\\\\\" + Norm + \"\\\\Longitudinal\\\\ClusterLabels\\\\\" + pat + \"_\" + tag + \".csv\")\n",
    "        df = df[[\"Feature\", \"Cluster\"]]\n",
    "        df = df.drop_duplicates()\n",
    "        # sort by cluster\n",
    "        df = df.sort_values(by=[\"Cluster\"])\n",
    "        # turn value counts into a dataframe\n",
    "        df = df[\"Cluster\"].value_counts().rename_axis(\"Cluster\").reset_index(name=\"Counts\")\n",
    "        # set PatID as index\n",
    "        df[\"PatID\"] = pat\n",
    "        # set PatID as index\n",
    "        df.set_index(\"PatID\", inplace=True)\n",
    "            \n",
    "        # append to result\n",
    "        df_result = df_result.append(df, ignore_index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # get number of clusters per patient\n",
    "    df_numclust= df_result.groupby(\"PatID\")[\"Cluster\"].count()\n",
    "    \n",
    "    # get number of clusters with more than 3 features\n",
    "    df_stable = df_result[df_result[\"Counts\"] > 3]\n",
    "    df_stable = df_stable.groupby(\"PatID\")[\"Cluster\"].count()\n",
    "    \n",
    "    # merge number of clusters with more than 3 features and number of clusters\n",
    "    df_numclust = df_numclust.rename_axis(\"PatID\").reset_index(name=\"NumClusters\")\n",
    "    df_stable = df_stable.rename_axis(\"PatID\").reset_index(name=\"NumStableClusters\")\n",
    "    df_numclust = pd.merge(df_numclust, df_stable, on=\"PatID\")\n",
    "    # get mean number of clusters\n",
    "    meanclust = df_numclust[\"NumClusters\"].mean()\n",
    "    # get mean number of stable clusters\n",
    "    meanstable = df_numclust[\"NumStableClusters\"].mean()\n",
    "    # get mean number of features per cluster\n",
    "    df_numfts = df_result.groupby(\"PatID\")[\"Counts\"].mean()\n",
    "    df_numfts = df_numfts.rename_axis(\"PatID\").reset_index(name=\"MeanFeaturesperCluster\")\n",
    "    df_numclust = pd.merge(df_numclust, df_numfts, on=\"PatID\")\n",
    "    # get mean number of features per stable cluster\n",
    "    df_numfts = df_result[df_result[\"Counts\"] > 3]\n",
    "    df_numfts = df_numfts.groupby(\"PatID\")[\"Counts\"].mean()\n",
    "    df_numfts = df_numfts.rename_axis(\"PatID\").reset_index(name=\"MeanFeaturesperStableCluster\")\n",
    "    df_numclust = pd.merge(df_numclust, df_numfts, on=\"PatID\")\n",
    "\n",
    "    \n",
    "    print(\"Mean number of clusters: \" + str(meanclust))\n",
    "    print(\"Mean number of stable clusters: \" + str(meanstable))\n",
    "    print(\"Mean number of features per cluster: \" + str(df_numclust[\"MeanFeaturesperCluster\"].mean()))\n",
    "    print(\"Mean number of features per stable cluster: \" + str(df_numclust[\"MeanFeaturesperStableCluster\"].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean number of clusters: 12.85\n",
      "Mean number of stable clusters: 7.3\n",
      "Mean number of features per cluster: 4.717774541634837\n",
      "Mean number of features per stable cluster: 6.828075396825396\n"
     ]
    }
   ],
   "source": [
    "root = \"E:\\\\\"\n",
    "Norm = \"HM-FS\"\n",
    "output = False\n",
    "tag = \"Baseline\"\n",
    "ClusterCount(root, Norm, output, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean number of clusters: 10.05\n",
      "Mean number of stable clusters: 7.6\n",
      "Mean number of features per cluster: 5.91787878787879\n",
      "Mean number of features per stable cluster: 7.10952380952381\n"
     ]
    }
   ],
   "source": [
    "root = \"E:\\\\\"\n",
    "Norm = \"HM-FS\"\n",
    "output = False\n",
    "tag = \"BaselineRS\"\n",
    "ClusterCount(root, Norm, output, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean number of clusters: 15.25\n",
      "Mean number of stable clusters: 6.6\n",
      "Mean number of features per cluster: 4.013792871645038\n",
      "Mean number of features per stable cluster: 6.717460317460318\n"
     ]
    }
   ],
   "source": [
    "root = \"E:\\\\\"\n",
    "Norm = \"HM-FS\"\n",
    "output = False\n",
    "tag = \"t_val_15\"\n",
    "ClusterCount(root, Norm, output, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 653  713  826 1029 1302 1431 1481 1540 1553 1601 1642  829]\n",
      "Pat: 752 Timepoints: 4, Scans: ['MR5' 'MR9' 'MR12' 'MR14']\n",
      "Pat: 1088 Timepoints: 4, Scans: ['MR10' 'MR13' 'MR19' 'MR25']\n",
      "Pat: 1089 Timepoints: 4, Scans: ['MR6' 'MR12' 'MR15' 'MR20']\n",
      "Pat: 1118 Timepoints: 4, Scans: ['MR5' 'MR10' 'MR15' 'MR20']\n",
      "Pat: 1303 Timepoints: 4, Scans: ['MR5' 'MR8' 'MR13' 'MR19']\n",
      "Pat: 1307 Timepoints: 4, Scans: ['MR6' 'MR11' 'MR14' 'MR18']\n",
      "Pat: 1464 Timepoints: 4, Scans: ['MR1' 'MR3' 'MR4' 'MR5']\n",
      "Pat: 955 Timepoints: 4, Scans: ['MR1' 'MR6' 'MR16' 'MR22']\n",
      "[752, 1088, 1089, 1118, 1303, 1307, 1464, 955]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"E:\\\\Aaron\\\\ProstateMRL\\\\Data\\\\Paper1\\\\HM-FS\\\\Features\\\\Longitudinal_All_fts_Baseline.csv\")\n",
    "ok_pats = df.loc[df[\"Fraction\"] == 5][\"PatID\"].unique()\n",
    "# need_pats = df.loc[df[\"Fraction\"] == 0][\"PatID\"].unique()\n",
    "print(ok_pats)\n",
    "need_pats = []\n",
    "#need_pats = [x for x in need_pats if x not in ok_pats]\n",
    "#print(need_pats)\n",
    "\n",
    "for pat in df[\"PatID\"].unique():\n",
    "    tps = len(df.loc[df[\"PatID\"] == pat][\"Fraction\"].unique())\n",
    "    Scans = df.loc[df[\"PatID\"] == pat][\"Scan\"].unique()\n",
    "    if tps < 5:\n",
    "        print(\"Pat: {} Timepoints: {}, Scans: {}\".format(pat, tps, Scans))\n",
    "        need_pats.append(pat)\n",
    "print(need_pats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PR-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7360ff227b89f60dd61b1b8bc2ef1c638b87e6764dd45fc98e42ea5accfcbf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
